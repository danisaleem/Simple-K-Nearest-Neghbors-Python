{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Below is an example how data preprocessing can be achieved with pandas module\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "train = pd.read_csv('trainData.csv',  dtype={'Color': str,'Radius (cm)':float,'Weight (grams)':float})\n",
    "#########################  DATA Preprocessing  #############################\n",
    "    \n",
    "# drop duplicated rows\n",
    "train = train.drop_duplicates()\n",
    "    \n",
    "# replace zeros entries with np.nan\n",
    "train = train.replace(0,np.nan)\n",
    "train = train.dropna() # drop all nan entiries \n",
    "    \n",
    "# transform the nominal feature (color) to dummy\n",
    "newCols = pd.get_dummies(train.iloc[:,0]) \n",
    "train = pd.concat([newCols, train], axis=1) # add them to the transfomed columns to the beggining  of the data frame\n",
    "train = train.drop(train.columns[3], axis = 1) # drop nominal column (color)    \n",
    "\n",
    "## normalization\n",
    "min_radius = min(train.iloc[:,3])\n",
    "max_radius = max(train.iloc[:,3])\n",
    "train['Radius (cm)'] = list(map(lambda x: (float(x)-min_radius)/(max_radius-min_radius), train.iloc[:,3]))\n",
    "\n",
    "## normalization\n",
    "min_weight = min(train.iloc[:,4])\n",
    "max_weight = max(train.iloc[:,4])\n",
    "train['Weight (grams)'] = list(map(lambda x: (float(x)-min_weight)/(max_weight-min_weight), train.iloc[:,4]))\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test = pd.read_csv('testData.csv',  dtype={'Color': str,'Radius (cm)':float,'Weight (grams)':float})\n",
    "\n",
    "#########################  DATA Preprocessing  #############################\n",
    "    \n",
    "# drop duplicated rows\n",
    "test= test.drop_duplicates()\n",
    "\n",
    "# transform the nominal feature (color) to dummy\n",
    "newCols=pd.get_dummies(test.iloc[:,0]) \n",
    "test = pd.concat([newCols, test], axis=1) # add them to the transfomed columns to the beggining  of the data frame\n",
    "test= test.drop(test.columns[3], axis = 1) # drop nominal column (color)    \n",
    "\n",
    "## normalization like training data\n",
    "test['Radius (cm)'] = list(map(lambda x: (float(x)-min_radius)/(max_radius-min_radius), test.iloc[:,3]))\n",
    "\n",
    "## normalization like training data\n",
    "test['Weight (grams)'] = list(map(lambda x: (float(x)-min_weight)/(max_weight-min_weight), test.iloc[:,4]))\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Classification with Manual K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    " \n",
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    #loop through train dataset and calcluate Euclidean distance between each train row and given test row \n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, K):\n",
    "    distances = list()\n",
    "    \n",
    "    for index, train_row in train.iterrows():\n",
    "        dist = euclidean_distance(train_row,test_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1]) # sort according to Euclidean distance\n",
    "    neighbors = list()\n",
    "    neighbors.clear()\n",
    "    for i in range(K): #getting only the K neighbours\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "\n",
    "# Make a classification prediction with neighbors\n",
    "def predict_classification(train, test_row, K):\n",
    "    neighbors = get_neighbors(train, test_row, K)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction\n",
    "\n",
    "# main program, method for easy calling\n",
    "def my_main_method(K):\n",
    "#     Testrows = test[['Green','Red','Yellow','Radius (cm)','Weight (grams)','Original (class)']]\n",
    "#     prediction_result = pd.DataFrame(data=None, columns=test.columns, index=None) # make similar dataframe without data\n",
    "\n",
    "    rows_list=[] # List to gether resultant rows\n",
    "    for index, rw in test.iterrows():\n",
    "        prediction = predict_classification(train, rw, K)     # get predicted class\n",
    "        rw[5]=prediction # update predicted class in test data prediction column\n",
    "        rows_list.append(rw)\n",
    "#         prediction_result.loc[-1] = rw # not working, have to use list    \n",
    "#         print('Expected %s, Got %s.' % (rw[-2], prediction))\n",
    "#     print(prediction_result)\n",
    "    prediction_result = pd.DataFrame(rows_list)\n",
    "    return prediction_result\n",
    "    \n",
    "    \n",
    "########################################################################################\n",
    "#######                start the program with user input                ################\n",
    "########################################################################################\n",
    "try:\n",
    "    K=int(input(\"Enter Value for K:\"))\n",
    "except ValueError:\n",
    "    print(\"Error!!\")\n",
    "else:\n",
    "    prediction_result = my_main_method(K) # calling main method with value of K input by user\n",
    "prediction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculateing Precision\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# making method for easy calling\n",
    "def calculate_Precision(y_true, y_pred):    \n",
    "    return precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "y_true = prediction_result['Original (class)'].tolist()\n",
    "y_pred = prediction_result['Predicted (class)'].tolist()\n",
    "\n",
    "p=calculate_Precision(y_true, y_pred)\n",
    "print('precision = %.1f when K = %.d' % (p * 100, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  kNN Classification with Automatic K Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=1 # starting value of K\n",
    "max_K=len(train) # in order to avoid infinite loop. Setting max value for K equal to total datapoints\n",
    "program_precision=0 # initializa programs precision at start\n",
    "\n",
    "try:\n",
    "    Min_Precision=float(input(\"Enter minimum precision required:\"))\n",
    "    Min_Precision = Min_Precision/100 # turn into percentage value\n",
    "except ValueError:\n",
    "    print(\"Error!!\")\n",
    "else:\n",
    "    while program_precision < Min_Precision: \n",
    "#         print('Min_Precision %.3f' % (Min_Precision))\n",
    "#         print('program_precision %.3f' % (program_precision))\n",
    "        \n",
    "        prediction_result = my_main_method(K)  # calling main method with starting value of K=1\n",
    "\n",
    "        y_true = prediction_result['Original (class)'].tolist()\n",
    "        y_pred = prediction_result['Predicted (class)'].tolist()\n",
    "\n",
    "        # checking if output precision meets the criteria of min precision\n",
    "        program_precision = calculate_Precision(y_true, y_pred)\n",
    "        if program_precision < Min_Precision: # checking if we have reaced the required precision or not\n",
    "            K=K+1 # increase K to increase precision (hopefully)\n",
    "            \n",
    "            if K>max_K: # in order to avoid infinite loop\n",
    "                print('precision = %.1f when K = %.d' % (program_precision * 100, K))\n",
    "                print('')\n",
    "                print('*****************************************')                \n",
    "#                 print('Max K reached at at K = %.1f' % (K))\n",
    "                print('***********   Max K Reached   ***********')\n",
    "                print('*****************************************')\n",
    "                break\n",
    "                \n",
    "            prediction_result = my_main_method(K)  # calling main method again after increasing value of K\n",
    "            \n",
    "            #getting **UPDATED** results and predictions\n",
    "            y_true = prediction_result['Original (class)'].tolist()\n",
    "            y_pred = prediction_result['Predicted (class)'].tolist()\n",
    "            \n",
    "            program_precision = calculate_Precision(y_true, y_pred)    #calculating precision again\n",
    "            \n",
    "        print('precision = %.1f when K = %.d' % (program_precision * 100, K))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
